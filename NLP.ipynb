{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDfVctPVhVjc"
      },
      "source": [
        "# **Some basic NLP**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ur7o1phdcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f62b82-8524-42ac-e92f-2e8a4708488b"
      },
      "source": [
        "#Displaying English, French and Spanish stopwords\n",
        "import nltk as nltk\n",
        "from nltk.tokenize import word_tokenize , sent_tokenize\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')\n",
        "\n",
        "stopwords.words('french')\n",
        "\n",
        "stopwords.words('spanish')\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9A-AhZDV5LE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7699d57f-05ed-4fef-e080-b09b7fb081c7"
      },
      "source": [
        "#Lemmatizing \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer=WordNetLemmatizer()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUOImNCebj0v",
        "outputId": "955d81b9-e4e8-4da4-bd69-d17d99ad0c95"
      },
      "source": [
        "x=\"\"\"believes belief this crossing cross \"\"\"\n",
        "y=word_tokenize(x)\n",
        "nltk.pos_tag(y)\n",
        "for w in y:\n",
        " print(\"Lemma for\", w ,\"is :\", lemmatizer.lemmatize(w,pos=\"v\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma for believes is : believe\n",
            "Lemma for belief is : belief\n",
            "Lemma for this is : this\n",
            "Lemma for crossing is : cross\n",
            "Lemma for cross is : cross\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJUXwDhVYVCS",
        "outputId": "992bff19-bf7f-4d47-a5b4-9c23861a6095"
      },
      "source": [
        "#Stem words from other languages using the SnowballStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "#Langages supported By SnowballStemmer\n",
        "print(\" \".join(SnowballStemmer.languages)) \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQr0BWuGggv3",
        "outputId": "0e1ca092-49cf-46dc-d9ad-8d9113ba8836"
      },
      "source": [
        "#Stemming a french text\n",
        "text=\"\"\"Le traitement automatique du langage naturel est utilisé au quotidien pour des centaines d’usages différents\"\"\"\n",
        "french_words=word_tokenize(text) #Word tokenizing\n",
        "stemmer = SnowballStemmer(\"french\") # Choosing a language\n",
        "for i in french_words :\n",
        " print(stemmer.stem(i))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trait\n",
            "automat\n",
            "du\n",
            "langag\n",
            "naturel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PnyBY--hsIp",
        "outputId": "c4c77b1e-77ab-4973-8a39-d6c835ea4877"
      },
      "source": [
        "#Stemming a german text\n",
        "text1=\"\"\"L'elaborazione automatica del linguaggio naturale viene utilizzata quotidianamente per centinaia di usi divers\"\"\"\n",
        "italian_words=word_tokenize(text1) #Word tokenizing\n",
        "stemmer = SnowballStemmer(\"italian\") # Choosing a language\n",
        "for i in italian_words :\n",
        " print(stemmer.stem(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l'elabor\n",
            "automat\n",
            "del\n",
            "linguagg\n",
            "natural\n",
            "vien\n",
            "utilizz\n",
            "quotidian\n",
            "per\n",
            "centinai\n",
            "di\n",
            "usi\n",
            "divers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FViSoDlNiIRC",
        "outputId": "845f4e1f-ef17-4005-f25c-2ec3707b8c1c"
      },
      "source": [
        "#Stemming an arabic text\n",
        "text2=\"\"\"O processamento automático de linguagem natural é usado diariamente para centenas de usos diferentes \"\"\"\n",
        "portuguese_words=word_tokenize(text2) #Word tokenizing\n",
        "stemmer = SnowballStemmer(\"portuguese\") # Choosing a language\n",
        "for i in portuguese_words :\n",
        " print(stemmer.stem(i))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o\n",
            "process\n",
            "automát\n",
            "de\n",
            "linguag\n",
            "natural\n",
            "é\n",
            "usad\n",
            "diari\n",
            "par\n",
            "centen\n",
            "de\n",
            "usos\n",
            "diferent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo-F5L5xrwrv",
        "outputId": "a703b4d2-2967-4345-db40-caf983d0546a"
      },
      "source": [
        "#Finding definitions and examples for AI\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "syns = wordnet.synsets(\"AI\")\n",
        "print(\"Defination of the said word:\")\n",
        "print(syns[0].definition())\n",
        "print(\"\\nExamples of the word in use::\")\n",
        "print(syns[0].examples())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defination of the said word:\n",
            "an agency of the United States Army responsible for providing timely and relevant and accurate and synchronized intelligence to tactical and operational and strategic level commanders\n",
            "\n",
            "Examples of the word in use::\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKsnv0i9oPex",
        "outputId": "578ff8cb-2dac-4452-b695-d7a646b38e10"
      },
      "source": [
        "#Displaying the list of synonyms\n",
        "\n",
        "synonyms = [] \n",
        "for syn in wordnet.synsets(\"AI\"):\n",
        "    for l in syn.lemmas():\n",
        "        synonyms.append(l.name())\n",
        "print(set(synonyms))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Army_Intelligence', 'three-toed_sloth', 'artificial_insemination', 'artificial_intelligence', 'AI', 'ai', 'Bradypus_tridactylus'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKspt4EmqGl8",
        "outputId": "df38d749-50f2-4530-b1e6-d4f47e6dc222"
      },
      "source": [
        "#Finding antonyms and synonyms\n",
        "syn = list()\n",
        "ant = list()\n",
        "for synset in wordnet.synsets(\"Ugly\"):\n",
        "   for lemma in synset.lemmas():\n",
        "      syn.append(lemma.name())    \n",
        "      if lemma.antonyms():    \n",
        "       ant.append(lemma.antonyms()[0].name())\n",
        "print('Synonyms: ' + str(syn))\n",
        "print('Antonyms: ' + str(ant))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms: ['ugly', 'surly', 'ugly', 'despicable', 'ugly', 'vile', 'slimy', 'unworthy', 'worthless', 'wretched', 'atrocious', 'frightful', 'horrifying', 'horrible', 'ugly']\n",
            "Antonyms: ['beautiful']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poeowb2Ax9Zd",
        "outputId": "72a6b9f1-bf9d-4983-d2eb-646e1a3099b7"
      },
      "source": [
        "#Tokenize sentences using sent_tokenize\n",
        "sntc=\"\"\"Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can\"\"\"\n",
        "#Sentence Tokenization\n",
        "sent_tokenize(sntc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2miOnmhygm8",
        "outputId": "dc16159f-2921-49c8-86b8-f027df666c60"
      },
      "source": [
        "#Word tokenization\n",
        "word_tokenize(sntc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'refers',\n",
              " 'to',\n",
              " 'the',\n",
              " 'branch',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'science—and',\n",
              " 'more',\n",
              " 'specifically',\n",
              " ',',\n",
              " 'the',\n",
              " 'branch',\n",
              " 'of',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'or',\n",
              " 'AI—concerned',\n",
              " 'with',\n",
              " 'giving',\n",
              " 'computers',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'text',\n",
              " 'and',\n",
              " 'spoken',\n",
              " 'words',\n",
              " 'in',\n",
              " 'much',\n",
              " 'the',\n",
              " 'same',\n",
              " 'way',\n",
              " 'human',\n",
              " 'beings',\n",
              " 'can']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O8S3Xr-y2Zm",
        "outputId": "2c6766f8-0e47-4c14-80fe-2ff26f34187a"
      },
      "source": [
        "#Tokenize sentences using sent_tokenize.\n",
        "phrase=\"\"\" Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can\"\"\"\n",
        "sent_tokenize(phrase)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVRhyRofzatC",
        "outputId": "e15bf7d8-ebd6-42cd-d9ce-d8e3b4444fbf"
      },
      "source": [
        "#Tokenize phrases in another language \n",
        "portuguese_sent=\"\"\"O processamento automático de linguagem natural é usado diariamente para centenas de usos diferentes\"\"\"\n",
        "sent_tokenize(portuguese_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O processamento automático de linguagem natural é usado diariamente para centenas de usos diferentes']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uquvniAE0D0r"
      },
      "source": [
        "Observation :  \n",
        "\n",
        "-\"Sent_tokenize\" splits a text into sentences.\n",
        "\n",
        "-This intruction uses ponctuation (dots for example) to tokenize the sentences . \n",
        "\n",
        "-It doesn't take in consideration the langage .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAK3GITo0ngF",
        "outputId": "6aefdd2e-e122-4f50-9431-365620d37797"
      },
      "source": [
        "#Tokenizing sentence with abbreviation\n",
        "sent1=\"\"\" Natural language processing (NLP) strives to build machines that understand and respond to text or voice data. In much the same way humans do\"\"\"\n",
        "sent_tokenize(sent1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Natural language processing (NLP) strives to build machines that understand and respond to text or voice data.',\n",
              " 'In much the same way humans do']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9-ARlDW13sA"
      },
      "source": [
        "Observation : \n",
        "\n",
        "Abbreviations are not taking in consideration when we tokenize sentences meaning , they don't disturb or have an impact on the tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p8Fzhud2pg8",
        "outputId": "437780a2-d02e-49a6-91e8-d88f764b4f44"
      },
      "source": [
        "#Word Tokenization\n",
        "word_tokenize(sent1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'strives',\n",
              " 'to',\n",
              " 'build',\n",
              " 'machines',\n",
              " 'that',\n",
              " 'understand',\n",
              " 'and',\n",
              " 'respond',\n",
              " 'to',\n",
              " 'text',\n",
              " 'or',\n",
              " 'voice',\n",
              " 'data',\n",
              " '.',\n",
              " 'In',\n",
              " 'much',\n",
              " 'the',\n",
              " 'same',\n",
              " 'way',\n",
              " 'humans',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuaQVXTf3HbM"
      },
      "source": [
        "Observation :\n",
        "\n",
        " \n",
        "\n",
        "*   \"Word_tokenise\" splits in the sentences into words.\n",
        "\n",
        "\n",
        "- Dots are considered as words.\n",
        "- Brackets are considered as words.\n",
        "-Commas are considered as words."
      ]
    }
  ]
}